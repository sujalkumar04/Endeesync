# EndeeSync Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# Application
# =============================================================================
APP_NAME=EndeeSync
APP_VERSION=0.1.0
DEBUG=false
LOG_LEVEL=INFO

# =============================================================================
# Server
# =============================================================================
HOST=0.0.0.0
PORT=8000

# =============================================================================
# Embedding Model
# =============================================================================
# Options: all-MiniLM-L6-v2, BAAI/bge-small-en-v1.5
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# =============================================================================
# Chunking
# =============================================================================
CHUNK_SIZE=400
CHUNK_OVERLAP=50

# =============================================================================
# Vector Store (Endee)
# =============================================================================
ENDEE_DB_PATH=./data/endee
ENDEE_COLLECTION_NAME=memories

# =============================================================================
# Search
# =============================================================================
DEFAULT_TOP_K=5
SIMILARITY_THRESHOLD=0.0

# =============================================================================
# LLM Configuration (Groq)
# =============================================================================
# Provider: groq, openai, anthropic, local
LLM_PROVIDER=groq

# Groq API Key (get from console.groq.com)
LLM_API_KEY=your-groq-api-key-here

# Groq Models:
# - llama-3.1-8b-instant (fast, good for most tasks)
# - llama-3.1-70b-versatile (more capable)
# - mixtral-8x7b-32768 (good for long context)
# - gemma2-9b-it (Google's model)
LLM_MODEL=llama-3.1-8b-instant

# Custom base URL (not needed for Groq)
# LLM_BASE_URL=

# Generation settings
LLM_MAX_TOKENS=1024
LLM_TEMPERATURE=0.7

# =============================================================================
# CORS
# =============================================================================
# Comma-separated origins, or * for all
CORS_ORIGINS=*
